<!DOCTYPE html>
<html lang="it">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Trascrizione e Analisi Audio Avanzata</title>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jspdf/2.5.1/jspdf.umd.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/html-docx-js/0.3.1/html-docx.js"></script>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            padding: 20px;
        }

        .container {
            max-width: 1000px;
            margin: 0 auto;
            background: white;
            border-radius: 20px;
            padding: 30px;
            box-shadow: 0 20px 60px rgba(0,0,0,0.3);
        }

        h1 {
            color: #667eea;
            text-align: center;
            margin-bottom: 10px;
            font-size: 28px;
        }

        .subtitle {
            text-align: center;
            color: #6b7280;
            margin-bottom: 30px;
            font-size: 14px;
        }

        .tabs {
            display: flex;
            gap: 10px;
            margin-bottom: 30px;
            border-bottom: 2px solid #e5e7eb;
            flex-wrap: wrap;
        }

        .tab {
            padding: 12px 24px;
            background: none;
            border: none;
            border-bottom: 3px solid transparent;
            cursor: pointer;
            font-size: 16px;
            font-weight: 500;
            color: #6b7280;
            transition: all 0.3s;
        }

        .tab.active {
            color: #667eea;
            border-bottom-color: #667eea;
        }

        .tab-content {
            display: none;
        }

        .tab-content.active {
            display: block;
        }

        .upload-area {
            border: 3px dashed #d1d5db;
            border-radius: 12px;
            padding: 40px;
            text-align: center;
            margin-bottom: 20px;
            cursor: pointer;
            transition: all 0.3s;
        }

        .upload-area:hover {
            border-color: #667eea;
            background: #f9fafb;
        }

        .upload-area.dragover {
            border-color: #667eea;
            background: #eef2ff;
        }

        .upload-icon {
            font-size: 48px;
            margin-bottom: 10px;
        }

        .btn {
            padding: 12px 24px;
            border: none;
            border-radius: 10px;
            font-size: 15px;
            font-weight: 600;
            cursor: pointer;
            transition: all 0.3s ease;
            display: inline-flex;
            align-items: center;
            justify-content: center;
            gap: 8px;
            margin: 5px;
        }

        .btn-primary {
            background: #667eea;
            color: white;
        }

        .btn-primary:hover {
            background: #5568d3;
            transform: translateY(-2px);
            box-shadow: 0 5px 15px rgba(102, 126, 234, 0.4);
        }

        .btn-success {
            background: #10b981;
            color: white;
        }

        .btn-success:hover {
            background: #059669;
        }

        .btn-success.recording {
            background: #ef4444;
            animation: pulse 1.5s infinite;
        }

        .btn-warning {
            background: #f59e0b;
            color: white;
        }

        .btn-warning:hover {
            background: #d97706;
        }

        .btn-info {
            background: #3b82f6;
            color: white;
        }

        .btn-secondary {
            background: #6b7280;
            color: white;
        }

        .btn:disabled {
            opacity: 0.5;
            cursor: not-allowed;
        }

        @keyframes pulse {
            0%, 100% { opacity: 1; }
            50% { opacity: 0.7; }
        }

        .transcript-area {
            background: #f9fafb;
            border: 2px solid #e5e7eb;
            border-radius: 12px;
            padding: 20px;
            min-height: 300px;
            max-height: 500px;
            overflow-y: auto;
            margin-bottom: 20px;
            font-size: 16px;
            line-height: 1.8;
            white-space: pre-wrap;
            word-wrap: break-word;
        }

        .transcript-area.empty {
            color: #9ca3af;
            font-style: italic;
            display: flex;
            align-items: center;
            justify-content: center;
        }

        textarea.transcript-area {
            width: 100%;
            font-family: inherit;
            resize: vertical;
        }

        .analysis-section {
            background: #f9fafb;
            border-radius: 12px;
            padding: 20px;
            margin-bottom: 20px;
        }

        .analysis-section h3 {
            color: #667eea;
            margin-bottom: 15px;
            display: flex;
            align-items: center;
            gap: 10px;
        }

        .analysis-content {
            color: #374151;
            line-height: 1.8;
        }

        .speaker-segment {
            margin-bottom: 15px;
            padding: 15px;
            background: white;
            border-radius: 8px;
            border-left: 4px solid #667eea;
        }

        .speaker-name {
            font-weight: 700;
            color: #667eea;
            margin-bottom: 8px;
        }

        .status {
            padding: 15px;
            border-radius: 10px;
            margin-bottom: 20px;
            font-weight: 500;
            display: none;
            align-items: center;
            gap: 10px;
        }

        .status.active {
            display: flex;
        }

        .status.success {
            background: #dcfce7;
            color: #166534;
        }

        .status.error {
            background: #fee2e2;
            color: #991b1b;
        }

        .status.info {
            background: #dbeafe;
            color: #1e40af;
        }

        .status.loading {
            background: #fef3c7;
            color: #92400e;
        }

        .spinner {
            border: 3px solid #f3f4f6;
            border-top: 3px solid #667eea;
            border-radius: 50%;
            width: 20px;
            height: 20px;
            animation: spin 1s linear infinite;
        }

        @keyframes spin {
            0% { transform: rotate(0deg); }
            100% { transform: rotate(360deg); }
        }

        .button-group {
            display: flex;
            flex-wrap: wrap;
            gap: 10px;
            margin-bottom: 20px;
            justify-content: center;
        }

        .info-box {
            background: #fef3c7;
            border-left: 4px solid #f59e0b;
            padding: 15px;
            border-radius: 8px;
            margin-bottom: 20px;
            font-size: 14px;
            color: #92400e;
        }

        .language-selector {
            margin-bottom: 20px;
        }

        .language-selector label {
            display: block;
            margin-bottom: 8px;
            color: #374151;
            font-weight: 500;
        }

        .language-selector select {
            width: 100%;
            padding: 12px;
            border: 2px solid #e5e7eb;
            border-radius: 8px;
            font-size: 16px;
            background: white;
        }

        #audioFileName {
            margin-top: 15px;
            font-weight: 600;
            color: #667eea;
        }

        @media (max-width: 768px) {
            .container {
                padding: 20px;
            }

            h1 {
                font-size: 24px;
            }

            .tabs {
                overflow-x: auto;
            }

            .tab {
                padding: 10px 16px;
                font-size: 14px;
                white-space: nowrap;
            }

            .btn {
                padding: 10px 16px;
                font-size: 14px;
            }

            .button-group {
                justify-content: stretch;
            }

            .button-group .btn {
                flex: 1;
                min-width: 150px;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>üé§ Trascrizione e Analisi Audio Pro</h1>
        <p class="subtitle">Trascrivi, analizza e identifica i parlanti con AI</p>

        <div class="status" id="status"></div>

        <div class="tabs">
            <button class="tab active" data-tab="record">üéôÔ∏è Registra</button>
            <button class="tab" data-tab="upload">üìÅ Carica File</button>
            <button class="tab" data-tab="paste">üìù Incolla Testo</button>
            <button class="tab" data-tab="analysis">üîç Analisi</button>
        </div>

        <!-- TAB REGISTRAZIONE -->
        <div class="tab-content active" id="tab-record">
            <div class="button-group">
                <button class="btn btn-warning" id="testMicBtn">
                    üîä Testa Microfono
                </button>
            </div>

            <div id="microphoneStatus" style="display: none; padding: 15px; border-radius: 10px; margin-bottom: 20px; font-weight: 500;">
                <div id="micStatusText"></div>
                <div id="micVolumeMeter" style="margin-top: 10px; display: none;">
                    <div style="background: #e5e7eb; border-radius: 5px; height: 10px; overflow: hidden;">
                        <div id="volumeBar" style="background: #10b981; height: 100%; width: 0%; transition: width 0.1s;"></div>
                    </div>
                </div>
            </div>

            <div id="micInstructions" class="info-box" style="display: none; background: #fee2e2; border-color: #ef4444; color: #991b1b;">
                <strong>‚ùå Permesso Microfono Negato</strong>
                <p style="margin-top: 10px;">Clicca l'icona üîí nella barra indirizzi ‚Üí Microfono ‚Üí Consenti ‚Üí Ricarica pagina</p>
            </div>

            <div class="language-selector">
                <label for="language">Lingua:</label>
                <select id="language">
                    <option value="it-IT">Italiano</option>
                    <option value="en-US">Inglese (US)</option>
                    <option value="en-GB">Inglese (UK)</option>
                    <option value="es-ES">Spagnolo</option>
                    <option value="fr-FR">Francese</option>
                    <option value="de-DE">Tedesco</option>
                </select>
            </div>

            <div class="button-group">
                <button class="btn btn-success" id="recordBtn">
                    <span id="recordBtnText">‚ñ∂Ô∏è Inizia Registrazione</span>
                </button>
            </div>

            <div class="transcript-area" id="liveTranscript">
                La trascrizione in tempo reale apparir√† qui...
            </div>
        </div>

        <!-- TAB CARICAMENTO FILE -->
        <div class="tab-content" id="tab-upload">
            <div class="upload-area" id="uploadArea">
                <div class="upload-icon">üì§</div>
                <h3>Trascina file audio o clicca</h3>
                <p style="color: #6b7280; margin-top: 10px;">MP3, WAV, M4A, OGG, WebM</p>
                <input type="file" id="audioFile" accept="audio/*" style="display: none;">
            </div>

            <div id="audioFileName"></div>

            <audio id="audioPlayer" controls style="width: 100%; margin: 20px 0; display: none;"></audio>

            <div class="language-selector">
                <label>Metodo:</label>
                <select id="transcriptionMethod">
                    <option value="free">üéôÔ∏è Gratuito</option>
                    <option value="whisper">‚≠ê Whisper API</option>
                </select>
            </div>

            <div id="whisperSection" style="display: none;">
                <div class="language-selector">
                    <label for="whisperLanguage">Lingua:</label>
                    <select id="whisperLanguage">
                        <option value="it">Italiano</option>
                        <option value="en">Inglese</option>
                        <option value="es">Spagnolo</option>
                        <option value="fr">Francese</option>
                        <option value="de">Tedesco</option>
                        <option value="">Auto</option>
                    </select>
                </div>

                <div style="margin: 20px 0;">
                    <input type="password" id="whisperApiKey" placeholder="Chiave API OpenAI (sk-...)" 
                           style="width: 100%; padding: 12px; border: 2px solid #e5e7eb; border-radius: 8px; font-size: 16px;">
                </div>
            </div>

            <div class="button-group">
                <button class="btn btn-primary" id="transcribeAudioBtn" disabled>
                    <span id="transcribeBtnText">üéØ Trascrivi</span>
                </button>
                <button class="btn btn-warning" id="stopTranscriptionBtn" style="display: none;">
                    ‚èπÔ∏è Ferma
                </button>
            </div>

            <div id="transcriptionProgress" style="display: none; margin: 20px 0;">
                <div style="background: #f3f4f6; border-radius: 8px; height: 8px; overflow: hidden;">
                    <div id="progressBar" style="background: #667eea; height: 100%; width: 0%; transition: width 0.3s;"></div>
                </div>
                <p id="progressText" style="text-align: center; margin-top: 10px; color: #6b7280;"></p>
            </div>

            <div id="liveFileTranscript" class="transcript-area" style="display: none; margin-top: 20px;">
                Trascrizione in corso...
            </div>
        </div>

        <!-- TAB INCOLLA TESTO -->
        <div class="tab-content" id="tab-paste">
            <p style="margin-bottom: 15px; color: #374151;">Incolla qui una trascrizione esistente per analizzarla:</p>
            <textarea class="transcript-area" id="pastedText" placeholder="Incolla qui il testo trascritto..." style="min-height: 300px;"></textarea>
            
            <div class="button-group">
                <button class="btn btn-primary" id="usePastedTextBtn">
                    ‚úì Usa questo testo
                </button>
            </div>
        </div>

        <!-- TAB ANALISI -->
        <div class="tab-content" id="tab-analysis">
            <div class="info-box" id="analysisInfo">
                üìä Carica o registra una trascrizione per iniziare
            </div>

            <div style="margin-bottom: 20px;">
                <div style="display: flex; gap: 10px;">
                    <input type="password" id="groqApiKey" placeholder="Chiave API Groq (gsk_...)" 
                           style="flex: 1; padding: 12px; border: 2px solid #e5e7eb; border-radius: 8px; font-size: 16px;">
                    <button class="btn btn-warning" id="testGroqKeyBtn">
                        üîç Testa Chiave
                    </button>
                </div>
                <p style="color: #6b7280; font-size: 13px; margin-top: 5px;">
                    <a href="https://console.groq.com/keys" target="_blank" style="color: #667eea;">Ottieni chiave GRATIS</a>
                </p>
            </div>

            <div class="transcript-area" id="mainTranscript" contenteditable="true">
                Il testo trascritto apparir√† qui. Puoi modificarlo prima dell'analisi.
            </div>

            <div class="button-group">
                <button class="btn btn-success" id="correctTextBtn" disabled>
                    ‚ú® Correggi Testo
                </button>
                <button class="btn btn-primary" id="summarizeBtn" disabled>
                    üìù Riassumi
                </button>
                <button class="btn btn-primary" id="analyzeBtn" disabled>
                    üîç Analizza
                </button>
                <button class="btn btn-primary" id="identifySpeakersBtn" disabled>
                    üë• Identifica Parlanti
                </button>
                <button class="btn btn-info" id="exportPdfBtn" disabled>
                    üìÑ PDF
                </button>
                <button class="btn btn-info" id="exportDocBtn" disabled>
                    üìù DOC
                </button>
                <button class="btn btn-secondary" id="clearBtn">
                    üóëÔ∏è Cancella
                </button>
            </div>

            <div id="analysisResults"></div>
        </div>
    </div>

    <script>
        // Variabili globali
        let recognition;
        let isRecording = false;
        let finalTranscript = '';
        let currentAudioFile = null;

        // Elementi DOM
        const tabs = document.querySelectorAll('.tab');
        const tabContents = document.querySelectorAll('.tab-content');
        const statusDiv = document.getElementById('status');
        const testMicBtn = document.getElementById('testMicBtn');
        const microphoneStatus = document.getElementById('microphoneStatus');
        const micStatusText = document.getElementById('micStatusText');
        const micVolumeMeter = document.getElementById('micVolumeMeter');
        const volumeBar = document.getElementById('volumeBar');
        const micInstructions = document.getElementById('micInstructions');
        const recordBtn = document.getElementById('recordBtn');
        const recordBtnText = document.getElementById('recordBtnText');
        const liveTranscript = document.getElementById('liveTranscript');
        const mainTranscript = document.getElementById('mainTranscript');
        const languageSelect = document.getElementById('language');
        const uploadArea = document.getElementById('uploadArea');
        const audioFile = document.getElementById('audioFile');
        const audioFileName = document.getElementById('audioFileName');
        const audioPlayer = document.getElementById('audioPlayer');
        const transcriptionMethod = document.getElementById('transcriptionMethod');
        const whisperSection = document.getElementById('whisperSection');
        const whisperLanguage = document.getElementById('whisperLanguage');
        const whisperApiKey = document.getElementById('whisperApiKey');
        const transcribeAudioBtn = document.getElementById('transcribeAudioBtn');
        const transcribeBtnText = document.getElementById('transcribeBtnText');
        const stopTranscriptionBtn = document.getElementById('stopTranscriptionBtn');
        const transcriptionProgress = document.getElementById('transcriptionProgress');
        const progressBar = document.getElementById('progressBar');
        const progressText = document.getElementById('progressText');
        const liveFileTranscript = document.getElementById('liveFileTranscript');
        const pastedText = document.getElementById('pastedText');
        const usePastedTextBtn = document.getElementById('usePastedTextBtn');
        const groqApiKey = document.getElementById('groqApiKey');
        const testGroqKeyBtn = document.getElementById('testGroqKeyBtn');
        const correctTextBtn = document.getElementById('correctTextBtn');
        const summarizeBtn = document.getElementById('summarizeBtn');
        const analyzeBtn = document.getElementById('analyzeBtn');
        const identifySpeakersBtn = document.getElementById('identifySpeakersBtn');
        const exportPdfBtn = document.getElementById('exportPdfBtn');
        const exportDocBtn = document.getElementById('exportDocBtn');
        const clearBtn = document.getElementById('clearBtn');
        const analysisResults = document.getElementById('analysisResults');
        const analysisInfo = document.getElementById('analysisInfo');

        // Gestione Tab
        tabs.forEach(tab => {
            tab.addEventListener('click', () => {
                const tabName = tab.dataset.tab;
                
                tabs.forEach(t => t.classList.remove('active'));
                tabContents.forEach(tc => tc.classList.remove('active'));
                
                tab.classList.add('active');
                document.getElementById(`tab-${tabName}`).classList.add('active');
            });
        });

        // Test Microfono
        let audioContext;
        let microphone;
        let analyser;
        let dataArray;
        let animationId;

        testMicBtn.addEventListener('click', async () => {
            microphoneStatus.style.display = 'block';
            micStatusText.textContent = 'üîÑ Richiesta permessi microfono...';
            microphoneStatus.style.background = '#dbeafe';
            microphoneStatus.style.color = '#1e40af';
            micInstructions.style.display = 'none';

            try {
                // Richiedi permessi microfono
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                
                // Permessi concessi!
                micStatusText.textContent = '‚úÖ Microfono attivo! Parla per vedere il livello audio.';
                microphoneStatus.style.background = '#d1fae5';
                microphoneStatus.style.color = '#065f46';
                micVolumeMeter.style.display = 'block';
                
                // Configura analizzatore audio
                audioContext = new (window.AudioContext || window.webkitAudioContext)();
                analyser = audioContext.createAnalyser();
                microphone = audioContext.createMediaStreamSource(stream);
                
                analyser.fftSize = 256;
                const bufferLength = analyser.frequencyBinCount;
                dataArray = new Uint8Array(bufferLength);
                
                microphone.connect(analyser);
                
                // Visualizza volume in tempo reale
                function updateVolume() {
                    analyser.getByteFrequencyData(dataArray);
                    
                    let sum = 0;
                    for (let i = 0; i < bufferLength; i++) {
                        sum += dataArray[i];
                    }
                    const average = sum / bufferLength;
                    const volume = (average / 255) * 100;
                    
                    volumeBar.style.width = volume + '%';
                    
                    animationId = requestAnimationFrame(updateVolume);
                }
                
                updateVolume();
                
                // Ferma il test dopo 10 secondi
                setTimeout(() => {
                    if (animationId) {
                        cancelAnimationFrame(animationId);
                    }
                    if (microphone) {
                        stream.getTracks().forEach(track => track.stop());
                        microphone.disconnect();
                    }
                    if (audioContext) {
                        audioContext.close();
                    }
                    
                    micStatusText.textContent = '‚úÖ Test completato! Il microfono funziona correttamente.';
                    micVolumeMeter.style.display = 'none';
                    
                    showStatus('‚úÖ Microfono configurato! Puoi iniziare a registrare', 'success');
                }, 10000);
                
            } catch (error) {
                console.error('Errore permessi microfono:', error);
                
                micStatusText.textContent = '‚ùå Impossibile accedere al microfono';
                microphoneStatus.style.background = '#fee2e2';
                microphoneStatus.style.color = '#991b1b';
                micInstructions.style.display = 'block';
                
                if (error.name === 'NotAllowedError' || error.name === 'PermissionDeniedError') {
                    showStatus('‚ùå Permesso microfono negato. Vedi istruzioni qui sotto.', 'error');
                } else if (error.name === 'NotFoundError') {
                    showStatus('‚ùå Nessun microfono trovato sul dispositivo', 'error');
                } else {
                    showStatus('‚ùå Errore accesso microfono: ' + error.message, 'error');
                }
            }
        });

        // Web Speech API per registrazione live
        if ('webkitSpeechRecognition' in window || 'SpeechRecognition' in window) {
            const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
            recognition = new SpeechRecognition();
            
            // Configurazione per audio lunghi senza interruzioni
            recognition.continuous = true;
            recognition.interimResults = true;
            recognition.maxAlternatives = 1;
            recognition.lang = languageSelect.value;

            recognition.onstart = () => {
                showStatus('üé§ Sto ascoltando...', 'loading');
            };

            recognition.onresult = (event) => {
                let interimTranscript = '';
                finalTranscript = '';

                for (let i = 0; i < event.results.length; i++) {
                    const transcript = event.results[i][0].transcript;
                    if (event.results[i].isFinal) {
                        finalTranscript += transcript + ' ';
                    } else {
                        interimTranscript += transcript;
                    }
                }

                liveTranscript.innerHTML = finalTranscript + '<span style="color: #9ca3af;">' + interimTranscript + '</span>';
                liveTranscript.classList.remove('empty');
            };

            recognition.onerror = (event) => {
                let errorMessage = 'Errore durante la trascrizione';
                
                if (event.error === 'no-speech') {
                    errorMessage = '‚ö†Ô∏è Nessun parlato rilevato. Riprova parlando pi√π forte.';
                } else if (event.error === 'audio-capture') {
                    errorMessage = '‚ùå Microfono non disponibile. Controlla le impostazioni.';
                } else if (event.error === 'not-allowed') {
                    errorMessage = '‚ùå Permesso microfono negato. Clicca su "üîä Testa Microfono" per abilitarlo.';
                    micInstructions.style.display = 'block';
                } else if (event.error === 'network') {
                    errorMessage = '‚ùå Errore di rete. Controlla la connessione internet.';
                } else {
                    errorMessage = `‚ùå Errore: ${event.error}`;
                }
                
                showStatus(errorMessage, 'error');
                stopRecording();
            };

            recognition.onend = () => {
                if (isRecording) {
                    recognition.start();
                }
            };

            languageSelect.addEventListener('change', () => {
                recognition.lang = languageSelect.value;
            });
        } else {
            showStatus('‚ùå Il tuo browser non supporta il riconoscimento vocale. Usa Chrome o Edge.', 'error');
            recordBtn.disabled = true;
        }

        // Registrazione
        recordBtn.addEventListener('click', () => {
            if (!isRecording) {
                startRecording();
            } else {
                stopRecording();
            }
        });

        function startRecording() {
            if (!recognition) return;
            
            // Prima richiedi i permessi del microfono esplicitamente
            navigator.mediaDevices.getUserMedia({ audio: true })
                .then(async stream => {
                    // Permessi OK, ferma lo stream (Web Speech API lo gestir√†)
                    stream.getTracks().forEach(track => track.stop());
                    
                    // Attiva wake lock per audio lunghi
                    await requestWakeLock();
                    
                    finalTranscript = '';
                    liveTranscript.textContent = 'Sto ascoltando...';
                    
                    isRecording = true;
                    recordBtn.classList.add('recording');
                    recordBtnText.textContent = '‚èπÔ∏è Ferma Registrazione';
                    
                    // Imposta recognition per gestire audio lunghi senza interruzioni
                    recognition.continuous = true;
                    recognition.interimResults = true;
                    recognition.maxAlternatives = 1;
                    
                    try {
                        recognition.start();
                    } catch (e) {
                        console.error('Errore avvio:', e);
                        showStatus('‚ö†Ô∏è Errore avvio registrazione. Riprova.', 'error');
                        stopRecording();
                    }
                })
                .catch(error => {
                    console.error('Errore permessi:', error);
                    showStatus('‚ùå Permesso microfono negato. Clicca su "üîä Testa Microfono" per abilitarlo.', 'error');
                    micInstructions.style.display = 'block';
                    micInstructions.scrollIntoView({ behavior: 'smooth', block: 'center' });
                });
        }

        function stopRecording() {
            if (!recognition) return;
            
            isRecording = false;
            recordBtn.classList.remove('recording');
            recordBtnText.textContent = '‚ñ∂Ô∏è Inizia Registrazione';
            
            recognition.stop();
            releaseWakeLock();
            
            if (finalTranscript.trim()) {
                mainTranscript.textContent = finalTranscript;
                enableAnalysisButtons();
                showStatus('‚úÖ Trascrizione completata!', 'success');
                
                setTimeout(() => {
                    document.querySelector('[data-tab="analysis"]').click();
                }, 2000);
            } else {
                liveTranscript.textContent = 'La trascrizione in tempo reale apparir√† qui...';
            }
        }

        // Upload file audio
        uploadArea.addEventListener('click', () => audioFile.click());
        
        uploadArea.addEventListener('dragover', (e) => {
            e.preventDefault();
            uploadArea.classList.add('dragover');
        });

        uploadArea.addEventListener('dragleave', () => {
            uploadArea.classList.remove('dragover');
        });

        uploadArea.addEventListener('drop', (e) => {
            e.preventDefault();
            uploadArea.classList.remove('dragover');
            
            const files = e.dataTransfer.files;
            if (files.length > 0) {
                handleAudioFile(files[0]);
            }
        });

        audioFile.addEventListener('change', (e) => {
            if (e.target.files.length > 0) {
                handleAudioFile(e.target.files[0]);
            }
        });

        function handleAudioFile(file) {
            if (!file.type.startsWith('audio/')) {
                showStatus('‚ùå Per favore carica un file audio valido', 'error');
                return;
            }

            currentAudioFile = file;
            audioFileName.textContent = `üìÅ File caricato: ${file.name} (${(file.size / 1024 / 1024).toFixed(2)} MB)`;
            
            // Mostra il player audio
            const url = URL.createObjectURL(file);
            audioPlayer.src = url;
            audioPlayer.style.display = 'block';
            
            transcribeAudioBtn.disabled = false;
            
            showStatus('‚úÖ File caricato! Seleziona il metodo e clicca "Trascrivi Audio"', 'success');
        }

        // Gestione metodo trascrizione
        transcriptionMethod.addEventListener('change', () => {
            if (transcriptionMethod.value === 'whisper') {
                whisperSection.style.display = 'block';
                transcribeBtnText.textContent = '‚≠ê Trascrivi con Whisper';
            } else {
                whisperSection.style.display = 'none';
                transcribeBtnText.textContent = 'üéØ Trascrivi (Gratis)';
            }
        });

        // Test Chiave Groq
        testGroqKeyBtn.addEventListener('click', async () => {
            const apiKey = groqApiKey.value.trim();
            
            if (!apiKey) {
                showStatus('‚ùå Inserisci una chiave API Groq', 'error');
                return;
            }

            showStatus('üîÑ Test chiave in corso...', 'loading');

            try {
                const response = await fetch("https://api.groq.com/openai/v1/chat/completions", {
                    method: "POST",
                    headers: {
                        "Content-Type": "application/json",
                        "Authorization": `Bearer ${apiKey}`
                    },
                    body: JSON.stringify({
                        model: "llama-3.1-8b-instant",
                        messages: [{ role: "user", content: "Test" }],
                        max_tokens: 10
                    })
                });

                if (response.ok) {
                    showStatus('‚úÖ Chiave valida! Groq API funzionante', 'success');
                } else {
                    const error = await response.json();
                    showStatus(`‚ùå Chiave non valida: ${error.error?.message || 'Errore sconosciuto'}`, 'error');
                }
            } catch (error) {
                showStatus('‚ùå Errore connessione. Verifica la chiave.', 'error');
            }
        });

        // Wake Lock per audio lunghi e schermo spento
        let wakeLock = null;

        async function requestWakeLock() {
            try {
                if ('wakeLock' in navigator) {
                    wakeLock = await navigator.wakeLock.request('screen');
                    console.log('Wake Lock attivato');
                }
            } catch (err) {
                console.log('Wake Lock non supportato:', err);
            }
        }

        function releaseWakeLock() {
            if (wakeLock) {
                wakeLock.release();
                wakeLock = null;
                console.log('Wake Lock rilasciato');
            }
        }

        // Trascrizione file audio
        transcribeAudioBtn.addEventListener('click', async () => {
            if (!currentAudioFile) return;

            const method = transcriptionMethod.value;

            if (method === 'whisper') {
                await transcribeWithWhisper();
            } else {
                await transcribeWithFreeMethod();
            }
        });

        // Trascrizione con Whisper API
        async function transcribeWithWhisper() {
            const apiKey = whisperApiKey.value.trim();
            
            if (!apiKey) {
                showStatus('‚ùå Inserisci la tua chiave API OpenAI', 'error');
                return;
            }

            showStatus('üöÄ Trascrizione in corso con Whisper API...', 'loading');
            transcriptionProgress.style.display = 'block';
            progressBar.style.width = '30%';
            progressText.textContent = 'Caricamento file...';

            try {
                const formData = new FormData();
                formData.append('file', currentAudioFile);
                formData.append('model', 'whisper-1');
                
                const lang = whisperLanguage.value;
                if (lang) {
                    formData.append('language', lang);
                }

                progressBar.style.width = '60%';
                progressText.textContent = 'Elaborazione in corso...';

                const response = await fetch('https://api.openai.com/v1/audio/transcriptions', {
                    method: 'POST',
                    headers: {
                        'Authorization': `Bearer ${apiKey}`
                    },
                    body: formData
                });

                progressBar.style.width = '90%';
                progressText.textContent = 'Quasi pronto...';

                if (!response.ok) {
                    const error = await response.json();
                    throw new Error(error.error?.message || 'Errore API Whisper');
                }

                const data = await response.json();
                const transcription = data.text;

                progressBar.style.width = '100%';
                progressText.textContent = 'Completato!';

                mainTranscript.textContent = transcription;
                enableAnalysisButtons();
                
                showStatus('‚úÖ Trascrizione completata con successo!', 'success');
                
                setTimeout(() => {
                    transcriptionProgress.style.display = 'none';
                    progressBar.style.width = '0%';
                    document.querySelector('[data-tab="analysis"]').click();
                }, 2000);

            } catch (error) {
                console.error('Errore Whisper:', error);
                showStatus(`‚ùå Errore: ${error.message}`, 'error');
                transcriptionProgress.style.display = 'none';
                progressBar.style.width = '0%';
            }
        }

        // Trascrizione gratuita - Riproduzione e Registrazione
        let fileTranscriptionActive = false;
        let fileTranscript = '';

        async function transcribeWithFreeMethod() {
            if (!recognition) {
                showStatus('‚ùå Web Speech API non supportata. Usa Chrome o Edge.', 'error');
                return;
            }

            // Attiva wake lock per audio lunghi
            await requestWakeLock();

            showStatus('üé§ Preparazione trascrizione gratuita...', 'loading');
            
            // Mostra l'area di trascrizione live
            liveFileTranscript.style.display = 'block';
            liveFileTranscript.textContent = 'Trascrizione in corso...';
            
            // Reset transcript
            fileTranscript = '';
            
            // Configura riconoscimento per audio lunghi senza interruzioni
            recognition.lang = languageSelect.value;
            recognition.continuous = true;
            recognition.interimResults = true;
            recognition.maxAlternatives = 1;

            // Setup event handlers per trascrizione file
            recognition.onresult = (event) => {
                let interimTranscript = '';

                for (let i = event.resultIndex; i < event.results.length; i++) {
                    const transcript = event.results[i][0].transcript;
                    if (event.results[i].isFinal) {
                        fileTranscript += transcript + ' ';
                    } else {
                        interimTranscript += transcript;
                    }
                }

                liveFileTranscript.innerHTML = fileTranscript + '<span style="color: #9ca3af;">' + interimTranscript + '</span>';
            };

            recognition.onerror = (event) => {
                console.error('Errore riconoscimento:', event.error);
                if (event.error === 'no-speech') {
                    // Continua senza errore per no-speech durante audio lungo
                    return;
                } else if (event.error === 'not-allowed') {
                    showStatus('‚ùå Permesso microfono negato. Vai alla tab "Registra" e clicca "üîä Testa Microfono".', 'error');
                    stopFileTranscription();
                } else if (event.error === 'audio-capture') {
                    showStatus('‚ùå Microfono non disponibile. Controlla le impostazioni del dispositivo.', 'error');
                    stopFileTranscription();
                } else if (event.error !== 'aborted') {
                    console.log(`Errore gestito: ${event.error}`);
                }
            };

            recognition.onend = () => {
                if (fileTranscriptionActive && !audioPlayer.paused) {
                    // Riavvia il riconoscimento se l'audio sta ancora riproducendo
                    try {
                        recognition.start();
                    } catch (e) {
                        console.log('Recognition restart:', e);
                    }
                } else if (fileTranscriptionActive) {
                    // Audio finito
                    stopFileTranscription();
                }
            };

            // Gestione fine audio
            audioPlayer.onended = () => {
                stopFileTranscription();
            };

            // Avvia trascrizione
            fileTranscriptionActive = true;
            transcribeAudioBtn.style.display = 'none';
            stopTranscriptionBtn.style.display = 'inline-flex';

            try {
                await recognition.start();
                showStatus('üéôÔ∏è Trascrizione attiva! Audio in partenza...', 'loading');
                
                // Aspetta per permettere al riconoscimento di attivarsi
                setTimeout(() => {
                    audioPlayer.currentTime = 0;
                    audioPlayer.play();
                    showStatus('‚ñ∂Ô∏è Audio in riproduzione - Trascrizione in corso...', 'loading');
                }, 1000);

            } catch (error) {
                console.error('Errore avvio trascrizione:', error);
                showStatus('‚ùå Errore avvio trascrizione', 'error');
                stopFileTranscription();
            }
        }

        // Ferma trascrizione file
        stopTranscriptionBtn.addEventListener('click', stopFileTranscription);

        function stopFileTranscription() {
            fileTranscriptionActive = false;
            
            if (recognition) {
                recognition.stop();
            }
            
            audioPlayer.pause();
            audioPlayer.currentTime = 0;
            
            releaseWakeLock();
            
            transcribeAudioBtn.style.display = 'inline-flex';
            stopTranscriptionBtn.style.display = 'none';

            if (fileTranscript.trim()) {
                mainTranscript.textContent = fileTranscript;
                enableAnalysisButtons();
                showStatus('‚úÖ Trascrizione completata!', 'success');
                
                setTimeout(() => {
                    document.querySelector('[data-tab="analysis"]').click();
                }, 2000);
            } else {
                liveFileTranscript.textContent = 'Nessuna trascrizione rilevata. Prova ad alzare il volume.';
                showStatus('‚ö†Ô∏è Nessun audio trascritto', 'error');
            }
        }

        // Incolla testo
        usePastedTextBtn.addEventListener('click', () => {
            const text = pastedText.value.trim();
            
            if (!text) {
                showStatus('‚ö†Ô∏è Incolla del testo prima di continuare', 'error');
                return;
            }

            mainTranscript.textContent = text;
            enableAnalysisButtons();
            showStatus('‚úÖ Testo caricato! Vai alla tab Analisi', 'success');
            
            setTimeout(() => {
                document.querySelector('[data-tab="analysis"]').click();
            }, 1500);
        });

        // Abilita pulsanti analisi
        function enableAnalysisButtons() {
            correctTextBtn.disabled = false;
            summarizeBtn.disabled = false;
            analyzeBtn.disabled = false;
            identifySpeakersBtn.disabled = false;
            exportPdfBtn.disabled = false;
            exportDocBtn.disabled = false;
            analysisInfo.style.display = 'none';
        }

        // Chiamate API Groq per analisi con Llama 3.1
        async function callGroqAPI(prompt) {
            const apiKey = groqApiKey.value.trim();
            
            if (!apiKey) {
                showStatus('‚ùå Inserisci la tua chiave API Groq nella sezione Analisi', 'error');
                return null;
            }

            showStatus('ü§ñ Elaborazione con Llama 3.1 (Groq)...', 'loading');
            
            try {
                const response = await fetch("https://api.groq.com/openai/v1/chat/completions", {
                    method: "POST",
                    headers: {
                        "Content-Type": "application/json",
                        "Authorization": `Bearer ${apiKey}`
                    },
                    body: JSON.stringify({
                        model: "llama-3.1-8b-instant",
                        messages: [
                            {
                                role: "user",
                                content: prompt
                            }
                        ],
                        temperature: 0.7,
                        max_tokens: 4096
                    })
                });

                if (!response.ok) {
                    const error = await response.json();
                    throw new Error(error.error?.message || `Errore API: ${response.status}`);
                }

                const data = await response.json();
                return data.choices[0].message.content;
            } catch (error) {
                console.error('Errore Groq API:', error);
                showStatus(`‚ùå Errore: ${error.message}`, 'error');
                return null;
            }
        }

        // Correzione testo con AI
        correctTextBtn.addEventListener('click', async () => {
            const text = mainTranscript.textContent.trim();
            if (!text) {
                showStatus('‚ö†Ô∏è Nessun testo da correggere', 'error');
                return;
            }

            const originalText = text; // Salva il testo originale

            const prompt = `Sei un esperto correttore di bozze. Correggi il seguente testo trascritto migliorandone:
1. **Grammatica e sintassi**: correggi errori grammaticali
2. **Punteggiatura**: aggiungi virgole, punti, punti interrogativi ed esclamativi dove necessario
3. **Ortografia**: correggi errori di battitura e parole mal trascritte
4. **Leggibilit√†**: dividi in paragrafi logici dove appropriato
5. **Errori di trascrizione comuni**: correggi parole simili foneticamente ma scritte male (es. "l'ho" vs "lo", "c'√®" vs "ce")

IMPORTANTE:
- Mantieni ESATTAMENTE lo stesso significato e contenuto
- NON aggiungere informazioni che non ci sono
- NON rimuovere contenuti importanti
- Mantieni lo stile conversazionale se presente
- Restituisci SOLO il testo corretto, senza commenti o spiegazioni aggiuntive

Testo da correggere:
${text}`;

            const result = await callGroqAPI(prompt);
            
            if (result) {
                // Mostra confronto
                const correctedText = result.trim();
                
                displayAnalysisResult('‚ú® Correzione Testo', `
                    <div style="margin-bottom: 20px;">
                        <div style="background: #fef3c7; padding: 15px; border-radius: 8px; border-left: 4px solid #f59e0b; margin-bottom: 20px;">
                            <strong>üí° Confronto:</strong> Qui sotto puoi vedere il testo originale e quello corretto. Clicca "Usa Testo Corretto" per sostituirlo.
                        </div>
                        
                        <h4 style="color: #6b7280; margin-bottom: 10px;">üìÑ Testo Originale:</h4>
                        <div style="background: #f3f4f6; padding: 15px; border-radius: 8px; margin-bottom: 20px; max-height: 200px; overflow-y: auto; border: 2px solid #e5e7eb;">
                            ${originalText.replace(/\n/g, '<br>')}
                        </div>
                        
                        <h4 style="color: #10b981; margin-bottom: 10px;">‚úÖ Testo Corretto:</h4>
                        <div style="background: #d1fae5; padding: 15px; border-radius: 8px; max-height: 200px; overflow-y: auto; border: 2px solid #10b981;">
                            ${correctedText.replace(/\n/g, '<br>')}
                        </div>
                        
                        <button id="useCorrectedText" 
                                style="margin-top: 20px; padding: 12px 24px; background: #10b981; color: white; border: none; border-radius: 10px; cursor: pointer; font-weight: 600; font-size: 15px; transition: all 0.3s;">
                            ‚úì Usa Testo Corretto
                        </button>
                    </div>
                `);
                
                // Aggiungi event listener al pulsante dopo che √® stato creato
                setTimeout(() => {
                    const useBtn = document.getElementById('useCorrectedText');
                    if (useBtn) {
                        useBtn.addEventListener('click', () => {
                            mainTranscript.textContent = correctedText;
                            showStatus('‚úÖ Testo corretto applicato!', 'success');
                            useBtn.textContent = '‚úì Applicato!';
                            useBtn.style.background = '#6b7280';
                            useBtn.disabled = true;
                        });
                        
                        useBtn.addEventListener('mouseenter', () => {
                            if (!useBtn.disabled) {
                                useBtn.style.background = '#059669';
                                useBtn.style.transform = 'translateY(-2px)';
                                useBtn.style.boxShadow = '0 5px 15px rgba(16, 185, 129, 0.4)';
                            }
                        });
                        
                        useBtn.addEventListener('mouseleave', () => {
                            if (!useBtn.disabled) {
                                useBtn.style.background = '#10b981';
                                useBtn.style.transform = 'translateY(0)';
                                useBtn.style.boxShadow = 'none';
                            }
                        });
                    }
                }, 100);
                
                showStatus('‚úÖ Correzione completata! Vedi il confronto qui sotto', 'success');
            }
        });

        // Riassunto
        summarizeBtn.addEventListener('click', async () => {
            const text = mainTranscript.textContent.trim();
            if (!text) return;

            const prompt = `Analizza e riassumi il seguente testo trascritto. Fornisci:
1. Un riassunto conciso (3-5 frasi)
2. I punti chiave principali
3. Eventuali temi o argomenti ricorrenti

Testo da analizzare:
${text}

Rispondi in italiano con una formattazione chiara e leggibile.`;

            const result = await callGroqAPI(prompt);
            
            if (result) {
                displayAnalysisResult('üìù Riassunto', result);
                showStatus('‚úÖ Riassunto completato!', 'success');
            }
        });

        // Analisi completa
        analyzeBtn.addEventListener('click', async () => {
            const text = mainTranscript.textContent.trim();
            if (!text) return;

            const prompt = `Effettua un'analisi approfondita del seguente testo trascritto. Includi:
1. **Analisi del contenuto**: temi principali, argomenti trattati
2. **Tono e stile**: formale/informale, emotivo/neutro
3. **Struttura**: organizzazione logica del discorso
4. **Insight chiave**: informazioni importanti, decisioni, azioni da intraprendere
5. **Sentiment**: analisi del sentimento generale

Testo da analizzare:
${text}

Rispondi in italiano con una formattazione chiara usando intestazioni e paragrafi ben strutturati.`;

            const result = await callGroqAPI(prompt);
            
            if (result) {
                displayAnalysisResult('üîç Analisi Completa', result);
                showStatus('‚úÖ Analisi completata!', 'success');
            }
        });

        // Identificazione parlanti
        identifySpeakersBtn.addEventListener('click', async () => {
            const text = mainTranscript.textContent.trim();
            if (!text) return;

            const prompt = `Analizza il seguente testo trascritto e identifica i diversi parlanti. Per ogni parlante identificato:
1. Assegna un nome (Parlante 1, Parlante 2, ecc. oppure suggerisci nomi se il contesto lo permette)
2. Segmenta il testo attribuendo ogni parte al parlante corretto
3. Fornisci un breve profilo o descrizione dello stile di ciascun parlante
4. Conta quante volte interviene ciascun parlante

Formatta l'output in modo chiaro, separando i segmenti di dialogo con il nome del parlante.

Testo da analizzare:
${text}

Rispondi in italiano con una formattazione chiara che evidenzi chiaramente i diversi parlanti.`;

            const result = await callGroqAPI(prompt);
            
            if (result) {
                displayAnalysisResult('üë• Identificazione Parlanti', result);
                showStatus('‚úÖ Identificazione parlanti completata!', 'success');
            }
        });

        // Mostra risultati analisi
        function displayAnalysisResult(title, content) {
            const section = document.createElement('div');
            section.className = 'analysis-section';
            section.innerHTML = `
                <h3>${title}</h3>
                <div class="analysis-content">${formatAnalysisContent(content)}</div>
            `;
            
            analysisResults.insertBefore(section, analysisResults.firstChild);
        }

        function formatAnalysisContent(content) {
            // Converti markdown-like formatting in HTML
            return content
                .replace(/\*\*([^*]+)\*\*/g, '<strong>$1</strong>')
                .replace(/\*([^*]+)\*/g, '<em>$1</em>')
                .replace(/\n\n/g, '</p><p>')
                .replace(/\n/g, '<br>')
                .replace(/^(.+)$/gm, '<p>$1</p>');
        }

        // Esporta PDF
        exportPdfBtn.addEventListener('click', () => {
            const text = mainTranscript.textContent.trim();
            if (!text) return;

            try {
                const { jsPDF } = window.jspdf;
                const doc = new jsPDF();
                
                // Aggiungi titolo
                doc.setFontSize(18);
                doc.text('Trascrizione Audio', 20, 20);
                
                // Aggiungi data
                doc.setFontSize(10);
                doc.text(`Data: ${new Date().toLocaleDateString('it-IT')}`, 20, 30);
                
                // Aggiungi testo trascritto
                doc.setFontSize(12);
                const splitText = doc.splitTextToSize(text, 170);
                doc.text(splitText, 20, 40);
                
                // Aggiungi analisi se presenti
                let yPosition = 40 + (splitText.length * 7);
                if (analysisResults.children.length > 0) {
                    yPosition += 20;
                    doc.setFontSize(16);
                    doc.text('Analisi', 20, yPosition);
                    yPosition += 10;
                    
                    doc.setFontSize(10);
                    Array.from(analysisResults.children).forEach(section => {
                        const title = section.querySelector('h3').textContent;
                        const content = section.querySelector('.analysis-content').textContent;
                        
                        if (yPosition > 270) {
                            doc.addPage();
                            yPosition = 20;
                        }
                        
                        doc.setFontSize(12);
                        doc.text(title, 20, yPosition);
                        yPosition += 7;
                        
                        doc.setFontSize(10);
                        const splitContent = doc.splitTextToSize(content, 170);
                        doc.text(splitContent, 20, yPosition);
                        yPosition += (splitContent.length * 5) + 10;
                    });
                }
                
                doc.save(`trascrizione_${new Date().toISOString().slice(0,10)}.pdf`);
                showStatus('‚úÖ PDF salvato con successo!', 'success');
            } catch (error) {
                console.error('Errore esportazione PDF:', error);
                showStatus('‚ùå Errore durante l\'esportazione PDF', 'error');
            }
        });

        // Esporta DOC
        exportDocBtn.addEventListener('click', () => {
            const text = mainTranscript.textContent.trim();
            if (!text) return;

            try {
                let htmlContent = `
                    <!DOCTYPE html>
                    <html>
                    <head>
                        <meta charset="UTF-8">
                        <title>Trascrizione Audio</title>
                    </head>
                    <body>
                        <h1>Trascrizione Audio</h1>
                        <p><strong>Data:</strong> ${new Date().toLocaleDateString('it-IT')}</p>
                        <hr>
                        <h2>Testo Trascritto</h2>
                        <p>${text.replace(/\n/g, '<br>')}</p>
                `;

                if (analysisResults.children.length > 0) {
                    htmlContent += '<hr><h2>Analisi</h2>';
                    
                    Array.from(analysisResults.children).forEach(section => {
                        const title = section.querySelector('h3').textContent;
                        const content = section.querySelector('.analysis-content').innerHTML;
                        htmlContent += `<h3>${title}</h3><div>${content}</div>`;
                    });
                }

                htmlContent += '</body></html>';

                const blob = htmlDocx.asBlob(htmlContent);
                const url = URL.createObjectURL(blob);
                const a = document.createElement('a');
                a.href = url;
                a.download = `trascrizione_${new Date().toISOString().slice(0,10)}.doc`;
                document.body.appendChild(a);
                a.click();
                document.body.removeChild(a);
                URL.revokeObjectURL(url);

                showStatus('‚úÖ DOC salvato con successo!', 'success');
            } catch (error) {
                console.error('Errore esportazione DOC:', error);
                showStatus('‚ùå Errore durante l\'esportazione DOC', 'error');
            }
        });

        // Cancella
        clearBtn.addEventListener('click', () => {
            if (confirm('Sei sicuro di voler cancellare tutto?')) {
                if (isRecording) stopRecording();
                if (fileTranscriptionActive) stopFileTranscription();
                
                finalTranscript = '';
                fileTranscript = '';
                mainTranscript.textContent = 'Il testo trascritto apparir√† qui. Puoi modificarlo prima dell\'analisi.';
                liveTranscript.textContent = 'La trascrizione in tempo reale apparir√† qui...';
                liveFileTranscript.style.display = 'none';
                liveFileTranscript.textContent = 'La trascrizione apparir√† qui in tempo reale...';
                pastedText.value = '';
                analysisResults.innerHTML = '';
                currentAudioFile = null;
                audioFileName.textContent = '';
                audioPlayer.style.display = 'none';
                audioPlayer.src = '';
                transcribeAudioBtn.disabled = true;
                transcribeAudioBtn.style.display = 'inline-flex';
                stopTranscriptionBtn.style.display = 'none';
                transcriptionProgress.style.display = 'none';
                progressBar.style.width = '0%';
                
                correctTextBtn.disabled = true;
                summarizeBtn.disabled = true;
                analyzeBtn.disabled = true;
                identifySpeakersBtn.disabled = true;
                exportPdfBtn.disabled = true;
                exportDocBtn.disabled = true;
                analysisInfo.style.display = 'block';
                
                showStatus('üóëÔ∏è Tutto cancellato', 'info');
            }
        });

        // Utility: mostra status
        function showStatus(message, type) {
            statusDiv.innerHTML = type === 'loading' 
                ? `<div class="spinner"></div><span>${message}</span>`
                : message;
            statusDiv.className = `status active ${type}`;
            
            if (type !== 'loading') {
                setTimeout(() => {
                    statusDiv.classList.remove('active');
                }, 5000);
            }
        }
    </script>
</body>
</html>
